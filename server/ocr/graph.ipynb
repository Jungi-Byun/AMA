{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ae8027-1b60-4ae2-882c-168d161bc18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install easyocr transformers torch\n",
    "!pip install requests opencv-python\n",
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e58dc8-3cf0-4c0f-9fc9-f2f398a8bf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade git+https://github.com/huggingface/transformers\n",
    "!pip install accelerate\n",
    "!pip install timm==1.0.13\n",
    "!pip install --upgrade accelerate transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb796b4-d6eb-4203-9209-be9c08ff633f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install langgraph\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9149d8-accb-48c9-a549-f4d04df3a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import requests\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc234d2-6d79-4dbe-bdbe-bbca7f937f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import pickle\n",
    "import editdistance\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac74a4-eb0e-477b-b30c-070a94e5e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import TypedDict, Any, Dict, List\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0a06ea-e7ef-455f-9c26-31c6c3090bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "import easyocr\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d2bb62-74b5-4e37-a445-2797a68f919f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad5c3ec7-23ab-4cd7-8dea-22c0676760cc",
   "metadata": {},
   "source": [
    "### LangGraph 구성\n",
    "OCR output → LLM → 요약문 → VectorDB search → 요약문 관련 문제 → LLM → 힌트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc88ad4-72ef-4122-85b8-8af35cf36085",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# curriculum_units.json 파일을 읽어서 변수로 불러오기\n",
    "with open(\"curriculum_units.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    curriculum_units = json.load(f)\n",
    "\n",
    "curriculum_titles = \"\\n\".join(item[\"title\"] for item in curriculum_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842a966a-391e-49bb-b127-48b93bf3c8ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 설명이 추가된 소단원 내용\n",
    "# curriculum_units = loaded_subtopics\n",
    "# curriculum_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70aae2c8-561c-4425-bc61-553cbab2f4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llM 모델 준비\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"LGAI-EXAONE/EXAONE-3.5-7.8B-Instruct\"\n",
    "\n",
    "llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dabeab-8373-4839-bc4e-99d6bb11a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_model_name = \"LGAI-EXAONE/EXAONE-3.5-2.4B-Instruct\"\n",
    "\n",
    "# small_llm_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     small_model_name,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     trust_remote_code=True,\n",
    "#     device_map=\"auto\"\n",
    "# )\n",
    "# small_tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a29b9a-d3b7-4b69-a722-392acfdf82a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    # trocr_result: str\n",
    "    easyocr_result: str\n",
    "    paddleocr_result: str\n",
    "    merged_text: str # OCR result들을 reconstruction한 결과\n",
    "    summary: str # LLM 요약문\n",
    "    is_math_related: bool # 수학 관련 여부\n",
    "    warning: str\n",
    "    valid_topic: str # 최종 선택 단원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b106ae6-6907-485c-aa6d-02a8f7dd4d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_bool(value):\n",
    "    return str(value).strip().lower() == \"yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52545da0-4370-4293-a019-f0c1c6e4c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ocr_merge(easy, paddle) -> str:\n",
    "    prompt = f\"\"\"다음은 동일한 교안 이미지에 대해 두 가지 OCR 엔진(EasyOCR, PaddleOCR)이 추출한 텍스트 결과입니다.  \n",
    "두 결과를 비교하여 잘못된 문장을 보완하고, 가능한 한 정확하고 자연스러운 하나의 최종 결과로 합쳐주세요.  \n",
    "문맥상 맞지 않거나 인식이 잘못된 단어는 유추하여 수정해 주세요.  \n",
    "최종 결과 텍스트를 먼저 출력하고, 마지막에 최종 결과가 수학 교육과 관련된 내용인지 여부를 아래와 같은 JSON 형식으로 출력해 주세요.\n",
    "\n",
    "```json\n",
    "{{\"is_math_related\": \"yes\"}}  # 또는 {{\"is_math_related\": \"no\"}}\n",
    "\n",
    "### EasyOCR 결과:\n",
    "{easy}\n",
    "\n",
    "### PaddleOCR 결과:\n",
    "{paddle}\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \n",
    "         \"content\":\"당신은 두 개의 OCR 결과(EasyOCR와 PaddleOCR)를 비교하여, \"\n",
    "                   \"최대한 정확하고 자연스러운 하나의 통합된 텍스트를 생성하는 전문 AI입니다.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    output_ids = llm_model.generate(\n",
    "        input_ids.to(\"cuda\"),\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=1024,\n",
    "        do_sample=False,\n",
    "    )\n",
    "\n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    result = output_text.split(\"[|assistant|]\")[-1].strip()\n",
    "\n",
    "    # ✅ is_math_related 값 추출\n",
    "    match = re.search(r'```json\\s*(\\{.*?\\})\\s*```', result, re.DOTALL)\n",
    "    if match:\n",
    "        try:\n",
    "            is_math_related_str = json.loads(match.group(1))[\"is_math_related\"]\n",
    "            is_math_related = is_math_related_str.lower() == \"yes\"\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"JSON 파싱 오류: {e}\")\n",
    "    else:\n",
    "        raise ValueError(\"⚠️ JSON 블록을 결과에서 찾을 수 없습니다.\")\n",
    "\n",
    "    # ✅ JSON 블록 제거한 최종 merged_text\n",
    "    merged_text = re.sub(r'```json\\s*\\{.*?\\}\\s*```', '', result, flags=re.DOTALL).strip()\n",
    "\n",
    "    # JSON 헤더 단독 제거\n",
    "    merged_text = re.sub(r'### JSON 결과:?\\s*', '', merged_text).strip()\n",
    "\n",
    "    # ✅ 출력 로그 (필요 시 제거 가능)\n",
    "    print(\"\\n✅ 통합 텍스트:\\n\", merged_text)\n",
    "    print(\"\\n✅ 수학 관련 여부:\", is_math_related_str)\n",
    "\n",
    "    # ✅ 반환\n",
    "    if not is_math_related:\n",
    "        return {\n",
    "            \"merged_text\": merged_text,\n",
    "            \"is_math_related\": False,\n",
    "            \"warning\": \"⚠️ 수학 관련 내용이 아닙니다. 그래프를 종료합니다.\"\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"merged_text\": merged_text,\n",
    "            \"is_math_related\": True\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63db41e-e3b5-4bee-a40c-7e833f086225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exaone_summary(text: str) -> str:\n",
    "    prompt = f\"\"\"당신은 초등학교 수학 교육 자료를 분석하고 분류하는 유능한 AI입니다.  \n",
    "아래 지침에 따라 교안 내용을 **간결하게 요약**하고, **가장 관련성 높은 단원**을 순차적으로 판단해 주세요.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 분석 단계 1: 교안 요약\n",
    "- 아래 교안을 기반으로 다음 정보를 추출하세요:\n",
    "  - 핵심 개념: 수학적 원리, 개념, 또는 활동\n",
    "  - 학습 목표: 학생이 이 수업을 통해 도달해야 할 목표\n",
    "\n",
    "## 🔎 분석 단계 2: 1차 후보 단원 선정 (단원명 기반)\n",
    "- 아래 제공된 초등 수학 단원 목록을 참고하여, **교안의 주제와 단원명 간 유사도**를 판단해  \n",
    "  관련성이 높은 단원 5개를 **정확한 단원명**으로 추려냅니다.\n",
    "\n",
    "## 🧠 분석 단계 3: 최종 관련 단원 선정 (내용 기반)\n",
    "- 위에서 추린 5개 단원의 핵심 개념과 학습 목표를 확인하고, **요약된 교안 내용과 가장 밀접한 단원 1개를 최종 선택**합니다.\n",
    "- 단순한 활동 중심보다는 개념을 설명한 단원이 더 적절합니다.\n",
    "- 단원의 명칭은 반드시 **초등 수학 단원 목록에서 일치하는 이름만 사용**하세요.\n",
    "\n",
    "---\n",
    "\n",
    "✅ 주의사항:\n",
    "- 단원명 외에는 부가 설명, 해설, 괄호 등을 포함하지 마세요.\n",
    "- 출력 형식을 반드시 지켜 주세요.\n",
    "\n",
    "---\n",
    "\n",
    "### Input (교안 원문):\n",
    "{text}\n",
    "\n",
    "---\n",
    "\n",
    "### 초등 수학 단원 목록:\n",
    "{curriculum_units}\n",
    "\n",
    "---\n",
    "\n",
    "### Output 형식:\n",
    "\n",
    "1. 요약 내용:\n",
    "- 핵심 개념: ...\n",
    "- 학습 목표: ...\n",
    "\n",
    "2. 1차 후보 단원 (단원명 기반 유사도 상위 5개, JSON 형식):\n",
    "```json\n",
    "{{\n",
    "  \"topic_1st\": \"여기에 단원명\",\n",
    "  \"topic_2st\": \"여기에 단원명\",\n",
    "  \"topic_3st\": \"여기에 단원명\",\n",
    "  \"topic_4st\": \"여기에 단원명\",\n",
    "  \"topic_5st\": \"여기에 단원명\"\n",
    "}}\n",
    "\n",
    "3. 최종 선택 단원 (내용 기반 유사도 최상위 1개, JSON 형식):\n",
    "```\n",
    "json\n",
    "{{\n",
    "  \"most_relevant_topic\": \"여기에 단원명\"\n",
    "}}\n",
    "\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"당신은 초등학교 교육자료를 잘 요약해 주는 유능한 AI입니다.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=True,\n",
    "            add_generation_prompt=True,\n",
    "            return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "    print(\"\\n🧮 입력 토큰 수:\", len(input_ids[0]))\n",
    "    \n",
    "    output_ids = llm_model.generate(\n",
    "        input_ids.to(\"cuda\"),\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        )\n",
    "\n",
    "    # ✅ 여기서 문자열로 디코딩\n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    # ✅ 문자열에 대해 split 적용\n",
    "    if \"[|assistant|]\" in output_text:\n",
    "        result = output_text.split(\"[|assistant|]\")[-1].strip()\n",
    "        print('\\n\\n✅ ', result)\n",
    "        return result\n",
    "\n",
    "    # print('\\n\\n', output_text.strip())\n",
    "    return output_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70559131-1562-4e2c-ad58-fc00ce07a3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import CrossEncoder\n",
    "\n",
    "# # CrossEncoder 모델 로딩 (한번만 하면 됨)\n",
    "# cross_encoder = CrossEncoder(\"sentence-transformers/all-MiniLM-L12-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d51c03b-be80-4c35-8d6f-cf4a1ebfc17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_summary_for_rerank(summary_text):\n",
    "    print(\"✅ 함수 시작\")\n",
    "\n",
    "    core_concept_match = re.search(\n",
    "        r\"^\\s*-\\s*\\**핵심 개념\\**:\\s*(.+?)\\s*^\\s*-\\s*\\**학습 목표\\**:\\s*(.+?)(?=\\n\\s*(?:\\d+\\.|\\Z))\",\n",
    "        summary_text,\n",
    "        re.DOTALL | re.MULTILINE,\n",
    "    )\n",
    "\n",
    "    if core_concept_match:\n",
    "        core_concept = core_concept_match.group(1).strip()\n",
    "        objective = core_concept_match.group(2).strip()\n",
    "        print(\"🔍 핵심개념:\", core_concept)\n",
    "        print(\"🔍 학습목표:\", objective)\n",
    "    else:\n",
    "        print(\"❌ 핵심개념/학습목표 추출 실패\")\n",
    "        return []\n",
    "\n",
    "    llm_text = f\"핵심 개념은 '{core_concept}'이며 학습 목표는 '{objective}'이다.\"\n",
    "\n",
    "    # 2) 관련 단원 JSON 추출 (설명 있는 항목 제거)\n",
    "    candidate_titles = []\n",
    "    for i in range(1, 6):\n",
    "        pattern = rf'\"topic_{i}st\"\\s*:\\s*\"([^\"]+)\"'\n",
    "        match = re.search(pattern, summary_text)\n",
    "        if match:\n",
    "            title = match.group(1)\n",
    "            candidate_titles.append(title)\n",
    "\n",
    "    if not candidate_titles:\n",
    "        print(\"❌ 관련 단원 추출 실패\")\n",
    "        return []\n",
    "\n",
    "    print(\"🎯 후보 단원:\", candidate_titles)\n",
    "\n",
    "    # 3) curriculum_units에서 title 기반으로 문장쌍 만들기\n",
    "    title2item = {item[\"title\"]: item for item in curriculum_units}\n",
    "    sentence_pairs = []\n",
    "    valid_candidates = []\n",
    "\n",
    "    print(\"llm_text: \", llm_text)\n",
    "    for title in candidate_titles:\n",
    "        item = title2item.get(title)\n",
    "        if item:\n",
    "            # candidate_text = f\"{item['title']} {item['core_concept']} {item['objective']}\"\n",
    "            candidate_text = f\"{item['title']} 단원의 핵심 개념은 '{item['core_concept']}' 이며, 학습 목표는 '{item['objective']}' 이다.\"\n",
    "            print(\"candidate_text: \", candidate_text)\n",
    "            sentence_pairs.append((llm_text, candidate_text))\n",
    "            valid_candidates.append(title)\n",
    "        else:\n",
    "            print(f\"🚫 curriculum_units에 없는 단원 패스: {title}\")\n",
    "\n",
    "    if not sentence_pairs:\n",
    "        print(\"❌ 유효한 소단원 없음\")\n",
    "        return []\n",
    "\n",
    "    # 4) CrossEncoder 예측 및 정렬\n",
    "    scores = cross_encoder.predict(sentence_pairs)\n",
    "    scored = sorted(zip(valid_candidates, scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print(\"✅ 최종 선정된 소단원:\", scored)\n",
    "\n",
    "    return scored  # List of (title, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835a68e4-d42b-457c-b5b4-9d1de95efbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_valid_topics(summary_text: str) -> list[str]:\n",
    "    # curriculum_units에 존재하는 title 집합\n",
    "    subtopic_titles = {item[\"title\"] for item in curriculum_units}\n",
    "    \n",
    "    valid_topics = []\n",
    "\n",
    "    # 최대 5개의 후보 주제 추출\n",
    "    for i in range(1, 6):\n",
    "        pattern = rf'\"topic_{i}st\"\\s*:\\s*\"([^\"]+)\"'\n",
    "        match = re.search(pattern, summary_text)\n",
    "        if match:\n",
    "            title = match.group(1)\n",
    "            if title in subtopic_titles:\n",
    "                print(f\"✅ 유효한 주제 발견: {title}\")\n",
    "                valid_topics.append(title)\n",
    "    \n",
    "    return valid_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8680ec-e6d6-49fb-9ad2-e39352b02650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_exaone_select(summary_text: str) -> str:\n",
    "    # 1. 요약문에서 핵심 개념과 학습 목표 추출 (각각 따로)\n",
    "    core_concept_match = re.search(\n",
    "        r\"-\\s*\\*?\\*?핵심 개념\\*?\\*?\\s*:\\s*(.+?)(?=\\n\\s*-\\s*\\*?\\*?학습 목표\\*?\\*?\\s*:)\",\n",
    "        summary_text,\n",
    "        re.DOTALL,\n",
    "    )\n",
    "\n",
    "    objective_match = re.search(\n",
    "        r\"-\\s*\\*?\\*?학습 목표\\*?\\*?\\s*:\\s*(.+?)(?=\\n\\s*\\d+\\.|\\n\\s*```|\\Z)\",\n",
    "        summary_text,\n",
    "        re.DOTALL,\n",
    "    )\n",
    "\n",
    "    if not core_concept_match or not objective_match:\n",
    "        print(\"❌ 핵심 개념/학습 목표 추출 실패\")\n",
    "        return \"\"\n",
    "\n",
    "    core_concept = core_concept_match.group(1).strip()\n",
    "    objective = objective_match.group(1).strip()\n",
    "\n",
    "    # 2. topic_1st ~ topic_5st 에서 후보 단원 제목 추출\n",
    "    candidate_titles = []\n",
    "    for i in range(1, 6):\n",
    "        pattern = rf'\"topic_{i}st\"\\s*:\\s*\"([^\"]+)\"'\n",
    "        match = re.search(pattern, summary_text)\n",
    "        if match:\n",
    "            candidate_titles.append(match.group(1))\n",
    "\n",
    "    if not candidate_titles:\n",
    "        print(\"❌ 후보 단원 추출 실패\")\n",
    "        return \"\"\n",
    "\n",
    "    # 3. 후보 중 curriculum_units에 존재하는 유효한 단원 필터링\n",
    "    title2item = {item[\"title\"]: item for item in curriculum_units}\n",
    "    valid_candidates = []\n",
    "    candidate_descriptions = []\n",
    "\n",
    "    for title in candidate_titles:\n",
    "        item = title2item.get(title)\n",
    "        if item:\n",
    "            description = (\n",
    "                f\"{item['title']}\\n\"\n",
    "                f\"핵심 개념: {item['core_concept']}\\n\"\n",
    "                f\"학습 목표: {item['objective']}\\n\"\n",
    "            )\n",
    "            valid_candidates.append(item[\"title\"])\n",
    "            candidate_descriptions.append(description)\n",
    "        else:\n",
    "            print(f\"🚫 curriculum_units에 없는 단원 패스: {title}\")\n",
    "\n",
    "    if not valid_candidates:\n",
    "        print(\"❌ 유효한 단원이 없습니다\")\n",
    "        return \"\"\n",
    "\n",
    "    # 4. 프롬프트 생성\n",
    "    curriculum_titles_text = \"\\n\".join(f\"- {desc}\" for desc in candidate_descriptions)\n",
    "\n",
    "    prompt = f\"\"\"다음은 초등 수학 수업 요약입니다. 설명과 **가장 관련 있는 개념 중심 단원 하나만** 정확하게 골라주세요.\n",
    "\n",
    "- 반드시 아래 목록에서 **하나만 선택**해야 하며, **정확한 단원명만** 작성해 주세요. (부연 설명, 괄호, 줄바꿈 없이 단순히 단원명만!)\n",
    "- **개념이나 정의를 중심으로 한 단원**을 우선적으로 고려해 주세요. 단순한 활동 중심보다는 개념을 설명한 단원이 더 적절합니다.\n",
    "- 아래와 같은 JSON 형식으로만 출력해 주세요.\n",
    "\n",
    "- **핵심 개념**: {core_concept}\n",
    "- **학습 목표**: {objective}\n",
    "\n",
    "다음은 소단원 목록입니다:\n",
    "{curriculum_titles_text}\n",
    "\n",
    "응답 예시:\n",
    "```json\n",
    "{{\n",
    "  \"valid_topic\": \"여기에 정확한 단원명을 작성해 주세요\"\n",
    "}}\n",
    "```\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \n",
    "         \"content\": \"당신은 초등학교 수학 교육 내용을 분석해 가장 관련 있는 단원을 추천하는 전문가 AI입니다.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    print(\"\\n🧮 입력 토큰 수:\", len(input_ids[0]))\n",
    "\n",
    "    output_ids = llm_model.generate(\n",
    "        input_ids.to(\"cuda\"),\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=False,\n",
    "    )\n",
    "\n",
    "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "    # print(\"📝 LLM 출력:\\n\", output_text)\n",
    "     \n",
    "    matches = re.findall(r'\"valid_topic\"\\s*:\\s*\"([^\"]+)\"', output_text)\n",
    "    \n",
    "    if matches:\n",
    "        selected_title = matches[-1].strip()\n",
    "        # print(\"valid_candidates: \", valid_candidates)\n",
    "    \n",
    "        if selected_title in [v.strip() for v in valid_candidates]:\n",
    "            print(\"✅ 최종 추천 단원:\", selected_title)\n",
    "            return selected_title\n",
    "        else:\n",
    "            print(f\"⚠️ 추천된 단원이 후보군에 없음: {selected_title}\")\n",
    "    else:\n",
    "        print(\"❌ 출력에서 valid_topic 추출 실패\")\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144c2af7-a333-4694-b202-771832a2a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_merge_node(state: dict) -> dict:\n",
    "    easy = state[\"easyocr_result\"]\n",
    "    paddle = state[\"paddleocr_result\"]\n",
    "    result = run_ocr_merge(easy, paddle)\n",
    "\n",
    "    output = {\n",
    "        \"merged_text\": result[\"merged_text\"],\n",
    "        \"is_math_related\": result[\"is_math_related\"]\n",
    "    }\n",
    "\n",
    "    # warning이 있는 경우에만 포함\n",
    "    if \"warning\" in result:\n",
    "        output[\"warning\"] = result[\"warning\"]\n",
    "        \n",
    "    return output\n",
    "\n",
    "def summarize_node(state: dict) -> dict:\n",
    "    input_text = state[\"merged_text\"]\n",
    "    summary = run_exaone_summary(input_text)\n",
    "    # parse_summary_for_rerank(summary)\n",
    "    # valid_tipics = extract_all_valid_topics(summary)\n",
    "    return {\"summary\": summary}\n",
    "\n",
    "def select_topic_node(state: dict) -> dict:\n",
    "    summary = state[\"summary\"]\n",
    "    valid_topic = run_exaone_select(summary)\n",
    "    return {\"valid_topic\": valid_topic}\n",
    "\n",
    "def end_with_warning_node(state: dict) -> dict:\n",
    "    print(state.get(\"warning\", \"⚠️ 비정상 종료\"))\n",
    "    return {}  # 결과 반환 없이 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d72de98-e6e3-4eb6-a255-3487724bff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)\n",
    "builder.add_node(\"ocr_merge\", RunnableLambda(ocr_merge_node)) # OCR 결과(EasyOCR와 PaddleOCR)를 통합\n",
    "builder.add_node(\"summarize\", RunnableLambda(summarize_node))\n",
    "builder.add_node(\"select_topic\", RunnableLambda(select_topic_node))\n",
    "builder.add_node(\"end_with_warning\", RunnableLambda(end_with_warning_node))\n",
    "\n",
    "builder.set_entry_point(\"ocr_merge\")\n",
    "\n",
    "# 수학 관련 여부에 따라 흐름 결정\n",
    "builder.add_conditional_edges(\n",
    "    \"ocr_merge\",\n",
    "    lambda state: \"end_with_warning\" if not state.get(\"is_math_related\", False) else \"summarize\"\n",
    ")\n",
    "\n",
    "builder.add_edge(\"summarize\", \"select_topic\")\n",
    "builder.add_edge(\"select_topic\", END)\n",
    "builder.add_edge(\"end_with_warning\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23424d4-560c-46e0-92bf-3e4bf01c148e",
   "metadata": {},
   "source": [
    "### OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b81597-062e-41d3-8254-9af674cbd35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) EasyOCR reader 생성 (한글+영어)\n",
    "reader = easyocr.Reader(['ko', 'en'], gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fd3ac-22de-4f2b-b846-a8289ddc17a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EasyOCR_from_file(file_path=None, url=None, show_image=True):\n",
    "    if file_path:\n",
    "        img = cv2.imread(file_path)\n",
    "    elif url:\n",
    "        response  = requests.get(url)\n",
    "        img = np.asarray(bytearray(response.content), dtype=\"uint8\")\n",
    "        img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n",
    "    else:\n",
    "        raise ValueError(\"Either file_path or url must be provided.\")\n",
    "\n",
    "    # BGR(OpenCV) -> RGB(PIL) 변환\n",
    "    img = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    _, binary = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # 4) 이미지에 OCR 수행\n",
    "    results = reader.readtext(binary)\n",
    "    \n",
    "    # 5) 결과 출력\n",
    "    # for bbox, text, prob in results:\n",
    "    #     print(f'Text: {text}, Confidence: {prob:.2f}')\n",
    "\n",
    "    # 이미지 출력\n",
    "    if show_image:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(binary, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # merged_text = \" \".join([text for _, text, _ in results])\n",
    "    return results, binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1590c9ba-c80d-4660-adb6-43c3486c6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PaddleOCR을 thread 방식이 아닌 직접 호출 방식으로 사용 시 instance 생성 필요\n",
    "ocr = PaddleOCR(text_recognition_model_name=\"korean_PP-OCRv5_mobile_rec\",\n",
    "                use_doc_orientation_classify=False,\n",
    "                use_doc_unwarping=False,\n",
    "                use_textline_orientation=True,  # 텍스트 방향 보정\n",
    "                text_det_box_thresh=0.4,        # 박스 임계값\n",
    "                text_rec_score_thresh=0.6,      # 인식 신뢰도 임계값\n",
    "                text_det_unclip_ratio=1.5,      # 텍스트 박스 확장 비율\n",
    "                text_det_thresh=0.3,             # 텍스트 감지 임계값\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e21b8b-6f3a-4a8e-b2b3-7476668b0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PaddleOCR_from_file(file_path=None, url=None, show_image=True):\n",
    "    if file_path:\n",
    "        img = cv2.imread(file_path)\n",
    "    elif url:\n",
    "        response = requests.get(url)\n",
    "        img = np.asarray(bytearray(response.content), dtype=\"uint8\")\n",
    "        img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n",
    "    else:\n",
    "        raise ValueError(\"Either file_path or url must be provided.\")\n",
    "\n",
    "    # 이미지 전처리\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    denoised = cv2.fastNlMeansDenoising(gray)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "    _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    padding = 30\n",
    "    padded_binary = cv2.copyMakeBorder(binary, padding, padding, padding, padding, cv2.BORDER_CONSTANT, value=255)\n",
    "    color_binary = cv2.cvtColor(padded_binary, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # OCR 수행\n",
    "    result = ocr.predict(color_binary)\n",
    "    ocr_result = result[0]\n",
    "\n",
    "    texts = ocr_result[\"rec_texts\"]        # 텍스트 인식 결과\n",
    "    scores = ocr_result[\"rec_scores\"]      # 인식 신뢰도\n",
    "    polys  = ocr_result[\"rec_polys\"]       # 텍스트 위치 (polygon)\n",
    "\n",
    "    # 이미지 출력\n",
    "    if show_image:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(color_binary)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return ' '.join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e8c38b-ee03-45d3-8275-94266d94cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PaddleOCR을 thread 방식으로 사용\n",
    "paddleocr_result = None\n",
    "\n",
    "def PaddleOCR_from_file_thread(file_path=None, url=None, show_image=True):\n",
    "    if file_path:\n",
    "        img = cv2.imread(file_path)\n",
    "    elif url:\n",
    "        response = requests.get(url)\n",
    "        img = np.asarray(bytearray(response.content), dtype=\"uint8\")\n",
    "        img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n",
    "    else:\n",
    "        raise ValueError(\"Either file_path or url must be provided.\")\n",
    "\n",
    "    ocr = PaddleOCR(text_recognition_model_name=\"korean_PP-OCRv5_mobile_rec\",\n",
    "                    use_doc_orientation_classify=False,\n",
    "                    use_doc_unwarping=False,\n",
    "                    use_textline_orientation=True,  # 텍스트 방향 보정\n",
    "                    text_det_box_thresh=0.4,        # 박스 임계값\n",
    "                    text_rec_score_thresh=0.6,      # 인식 신뢰도 임계값\n",
    "                    text_det_unclip_ratio=1.5,      # 텍스트 박스 확장 비율\n",
    "                    text_det_thresh=0.3,             # 텍스트 감지 임계값\n",
    "                   )#use_angle_cls\n",
    "\n",
    "    height, width = img.shape[:2]\n",
    "    print(f\"Width: {width}, Height: {height}\")\n",
    "\n",
    "    # 이미지 전처리\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    denoised = cv2.fastNlMeansDenoising(gray)\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "    _, binary = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    padding = 30\n",
    "    padded_binary = cv2.copyMakeBorder(binary, padding, padding, padding, padding, cv2.BORDER_CONSTANT, value=255)\n",
    "    color_binary = cv2.cvtColor(padded_binary, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # OCR 수행\n",
    "    result = ocr.predict(color_binary)\n",
    "    ocr_result = result[0]\n",
    "\n",
    "    texts = ocr_result[\"rec_texts\"]        # 텍스트 인식 결과\n",
    "    scores = ocr_result[\"rec_scores\"]      # 인식 신뢰도\n",
    "    polys  = ocr_result[\"rec_polys\"]       # 텍스트 위치 (polygon)\n",
    "\n",
    "    # 이미지 출력\n",
    "    if show_image:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(color_binary)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    global paddleocr_result\n",
    "    paddleocr_result = ' '.join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce3d69e-a4c7-4774-a2c9-3682d65fcfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 사전 준비: TrOCR 로딩\n",
    "# trocr_processor = TrOCRProcessor.from_pretrained(\"ddobokki/ko-trocr\") \n",
    "# trocr_model = VisionEncoderDecoderModel.from_pretrained(\"ddobokki/ko-trocr\")\n",
    "# trocr_tokenizer = AutoTokenizer.from_pretrained(\"ddobokki/ko-trocr\")\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# trocr_model = trocr_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d432fa-43b4-4c57-a939-9f83bbeaa5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def TROCR_from_file(detection_result, image):\n",
    "#     img_pil = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_GRAY2RGB))\n",
    "#     ocr_texts = []\n",
    "#     for (bbox, _, _) in detection_result:\n",
    "#         # bbox는 4개의 점 좌표로 주어짐 -> xmin, ymin, xmax, ymax로 변환\n",
    "#         pts = np.array(bbox).astype(int)\n",
    "#         xmin = np.min(pts[:, 0])\n",
    "#         ymin = np.min(pts[:, 1])\n",
    "#         xmax = np.max(pts[:, 0])\n",
    "#         ymax = np.max(pts[:, 1])\n",
    "    \n",
    "#         # 박스 영역 잘라내기\n",
    "#         cropped = img_pil.crop((xmin, ymin, xmax, ymax))\n",
    "    \n",
    "#         # TrOCR 추론\n",
    "#         pixel_values = trocr_processor(cropped, return_tensors=\"pt\").pixel_values.to(device)\n",
    "#         generated_ids = trocr_model.generate(pixel_values, max_length=64)\n",
    "#         generated_text = trocr_tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "#         generated_text = unicodedata.normalize(\"NFC\", generated_text)\n",
    "#         ocr_texts.append(generated_text)\n",
    "#         # print(\"Detected text:\", generated_text)\n",
    "\n",
    "#     return ' '.join(ocr_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63714fcd-b4d0-432a-a172-08e8025b9498",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b27156-af38-4db9-b069-bac7d498d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47bc49e-8d69-4783-9701-d50a9d6361bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221226131232394.png&imgGubun=D'\n",
    "file_path = ''\n",
    "paddle_thread = threading.Thread(target=PaddleOCR_from_file_thread, args=(file_path, url, False))\n",
    "paddle_thread.start()\n",
    "\n",
    "results, binary = EasyOCR_from_file(file_path, url)\n",
    "easyocr_result = \" \".join([text for _, text, _ in results])\n",
    "print(\"EasyOCR 결과: \", easyocr_result)\n",
    "\n",
    "# trocr_result = TROCR_from_file(results, binary)\n",
    "# print(\"\\nTROCR 결과: \", trocr_result)\n",
    "\n",
    "paddle_thread.join()\n",
    "\n",
    "# paddleocr_result = PaddleOCR_from_file(url=url, show_image=False)\n",
    "print(\"\\nPaddleOCR 결과: \", paddleocr_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f83e213-1277-4b6b-8f4a-a43343963fae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "result = graph.invoke({\"easyocr_result\": easyocr_result, \"paddleocr_result\":paddleocr_result})\n",
    "print(\"✅ 요약 및 문제 생성 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c9825a-b006-4bb4-871e-b8d3443a7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_graph(file_path=None, url=None):\n",
    "    paddle_thread = threading.Thread(target=PaddleOCR_from_file_thread, args=(file_path, url, False))\n",
    "    paddle_thread.start()\n",
    "    \n",
    "    results, binary = EasyOCR_from_file(file_path, url)\n",
    "    easyocr_result = \" \".join([text for _, text, _ in results])\n",
    "    print(\"EasyOCR 결과: \", easyocr_result)\n",
    "    \n",
    "    # trocr_result = TROCR_from_file(results, binary)\n",
    "    # print(\"\\nTROCR 결과: \", trocr_result)\n",
    "    \n",
    "    paddle_thread.join()\n",
    "    \n",
    "    # paddleocr_result = PaddleOCR_from_file(url=url, show_image=False)\n",
    "    print(\"\\nPaddleOCR 결과: \", paddleocr_result)\n",
    "    \n",
    "    result = graph.invoke({\"easyocr_result\": easyocr_result, \"paddleocr_result\":paddleocr_result})\n",
    "    print(\"✅ 요약 및 문제 생성 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e435554-be2c-4119-af86-948882fb674a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221222103639635.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f8971f-11f2-4b2d-bdfa-863877880e75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221222103435065.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511f806b-a447-45f2-923a-66f31a43a207",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20230428170405246.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c459c92f-1cf8-4917-8321-b8bbf87de416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221226131232394.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57efec0-bafc-4b52-811b-067c37ccf505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221222104929447.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e293d7b-067b-48ee-a93e-c2db87127608",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221226131610654.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d638099f-62b9-43ba-b229-9c0b271960d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221226131632718.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2362c017-29f6-4b26-8720-33a69541969a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221226132234942.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e4b00-86d4-4cf6-800c-29ce631c5eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221226132145911.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f202a7e-e61e-43e8-91bf-a956a2d72e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221222104708761.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c6ca53-fbc0-4eee-8c02-600c089dc027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221222104717403.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31b8ee-144f-4aa3-a3b8-4ec5beff86af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221229134742525.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3048b8e5-1cb1-4685-a393-446969e11dcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221229135232326.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d5451-9aad-41f0-bcda-484bc3a3bf00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20230425125336384.jpeg&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686d73b-1cbc-4744-8721-f07b091d3893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20230102143620114.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a3123-9e99-4abb-9ffc-9099fe8f29b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20230102143842371.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f283373-f04e-48fd-959b-a22f2106857c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://www.home-learn.co.kr/common/image.do?imgPath=newsroom&imgName=CK20221226131332329.png&imgGubun=D'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529739ce-8666-44aa-bd63-f0232cda90a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "file_path = 'Office_Lens_20161216-122020.jpg'\n",
    "test_graph(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bb1f0-e7fd-4952-89e4-8618e83d85f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "url = 'https://i.ytimg.com/vi/55d4n_dQxs4/maxresdefault.jpg?'\n",
    "test_graph(url=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24227b71-7fc2-4e81-b8e9-ca007680ed2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "file_path = 'ratio.png'\n",
    "test_graph(file_path=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e6b1c4-fe43-4dd0-a644-e1a3059fb959",
   "metadata": {},
   "source": [
    "### EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df38185-7de4-4d3d-9009-983743b5baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = f\"\"\"\n",
    "다음은 두 개의 OCR 결과(EasyOCR, PaddleOCR)를 통합하여 LLM이 생성한 텍스트입니다.  \n",
    "이 통합 결과가 원문에 기반하여 얼마나 정확하고 자연스러운지를 아래 기준에 따라 평가해 주세요.\n",
    "\n",
    "## 평가 항목:\n",
    "1. **정확성 (0~10점)**: 두 OCR 결과에 있는 정보를 충실히 반영했는가? 누락, 왜곡 없이 잘 통합했는가?\n",
    "2. **오류 수정 (0~10점)**: 인식 오류(오탈자, 잘못된 단어 등)를 문맥에 맞게 자연스럽게 수정했는가?\n",
    "3. **문장의 자연스러움 (0~10점)**: 결과 문장이 문법적으로 매끄럽고 읽기 쉬운가?\n",
    "\n",
    "각 항목을 0~10점으로 평가한 후, 전체 평균 점수(소수점 첫째 자리까지)를 **\"total_score\"**로 계산해 주세요.  \n",
    "\n",
    "## 출력 형식 (JSON):\n",
    "```json\n",
    "{{\n",
    "  \"evaluation\": {{\n",
    "    \"accuracy\": 8.5,\n",
    "    \"error_correction\": 9.0,\n",
    "    \"fluency\": 9.5,\n",
    "    \"total_score\": 9.0\n",
    "  }},\n",
    "  \"comments\": \"대부분의 정보를 잘 통합했으며, 오탈자 수정도 훌륭합니다. 다만 일부 숫자 인식 오류가 그대로 유지되어 감점되었습니다.\"\n",
    "}}\n",
    "\n",
    "## OCR 결과:\n",
    "### EasyOCR:\n",
    "{easyocr_result}\n",
    "\n",
    "### PaddleOCR:\n",
    "{paddleocr_result}\n",
    "\n",
    "## LLM 통합 결과:\n",
    "{result[\"merged_text\"]}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b130a85e-6f49-4b32-a572-f99a95be883c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# OpenAI 클라이언트 생성\n",
    "client = OpenAI(api_key=\"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\")  # 실제 키로 대체\n",
    "\n",
    "# GPT-4o-mini 호출\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"당신은 OCR 결과 통합을 전문으로 평가하는 전문가입니다. 두 가지 OCR 결과를 하나의 자연스럽고 정확한 문장으로 통합한 \n",
    "                        AI의 결과물을 평가하는 역할입니다. 평가 기준은 정확성, 오류 수정 능력, 문장의 자연스러움입니다. 이 기준에 따라 세심하게 \n",
    "                        평가하고 근거를 들어 설명해 주세요.\"\"\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": evaluation_prompt}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=256\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c83e4a1-e871-4a0d-adc1-d2a553c02207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68247169-1332-4eaf-95a5-418ed1763efb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cc09a7-e733-42a9-b751-e46f77546b7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a00008-a640-40cc-b628-327ad0de9323",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
